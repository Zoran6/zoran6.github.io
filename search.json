[{"title":"Redis哨兵模式容器化部署","path":"/2025/08/02/podman-redis/","content":"环境说明：MacBook（ARM架构）、本地Podman容器化部署 架构说明：结合生产环境最佳实践，本地部署将搭建3个Redis容器实例（一主二从）和3个Sentinel容器实例，用6个独立的容器实现Redis哨兵模式。 Podman容器部署细节： 6个容器在同一个共享网络中（IP不同但能够相互访问） 6个容器分别挂载到podman管理的持久化卷 Redis主节点分配固定的IP，从节点配置只读（读写分离） 挂载Redis容器的配置文件到本地（只需要读，不涉及权限问题） Sentinel容器基于Redis镜像，用dockerfile构建自己的镜像，把配置文件写入到镜像中，避免写权限问题 在启动时指定资源大小，0.2C0.2G（Mac本地环境，资源有限） 日志文件可以通过podman logs查看，不需要挂载到本地 搭建官方推荐工具redisinsight容器访问Redis节点 使用密钥管理工具Vault（可选） 配置热重载（无需重启）（可选） 一、部署Redis（一主二从）（一）创建持久化目录和共享网络# 创建持久化卷，把持久化卷交给podman去管理for vol in redis_master_data redis_slave1_data redis_slave2_data sentinel1_data sentinel2_data sentinel3_data; do podman volume create $voldone# 创建Redis哨兵模式共享网络podman network create redis_sentinel_net# （回退）删除持久化卷for vol in redis_master_data redis_slave1_data redis_slave2_data sentinel1_data sentinel2_data sentinel3_data; do podman volume rm $voldone# （回退）删除Redis哨兵模式共享网络podman network rm redis_sentinel_net （二）准备好配置文件在本地目录创建配置文件，挂载到Redis容器中 # 在本地目录创建配置文件/Users/zoran/dev/podman├── conf│ ├── redis-master.conf│ ├── redis-slave.conf 1. redis-master.conf# 绑定地址 (容器中建议注释掉或设为 0.0.0.0)# bind 127.0.0.1 -::1# 容器内允许所有网络接口访问bind 0.0.0.0# 监听端口 (默认6379)port 6379# 客户端访问密码requirepass zoran.wang@redis!# 主从复制密码，必须与requirepass密码一致masterauth zoran.wang@redis!# 保护模式 (生产环境应禁用)# 容器在内部网络运行时关闭protected-mode no# 工作目录 (挂载卷位置)dir /data # Podman卷挂载点# 日志文件 (容器中推荐输出到stdout) # logfile /var/log/redis/redis.log logfile # 输出到标准输出# 守护进程模式 (容器中必须设为 no)daemonize no # 容器需要前台运行# 进程PID文件 (容器中通常不需要)# pidfile /var/run/redis.pid# RDB快照配置 - 生产环境推荐save 900 1 # 900秒(15分钟)内至少1个键变化则保存save 300 10 # 300秒(5分钟)内至少10个键变化save 60 10000 # 60秒内至少10000个键变化# 后台保存出错时停止写入 (生产环境必须开启)stop-writes-on-bgsave-error yes# RDB文件压缩 (推荐开启)rdbcompression yes# RDB校验和 (推荐开启)rdbchecksum yes# RDB文件名dbfilename dump.rdb# AOF持久化配置 (推荐同时开启RDB+AOF)appendonly yes # 开启AOF# AOF文件名appendfilename appendonly.aof# AOF同步策略 (生产环境折衷方案)appendfsync everysec # 每秒同步，兼顾性能与安全# AOF重写时不同步 (提升性能)no-appendfsync-on-rewrite no# AOF自动重写阈值auto-aof-rewrite-percentage 100 # 增长100%时重写auto-aof-rewrite-min-size 64mb # 最小64MB触发重写# AOF加载时错误处理 (生产环境必须)aof-load-truncated yes 2. redis-slave.conf# 前面的内容和主节点配置一样，复制过来！！！！！！！# =======从节点配置========# 从节点复制配置 (启动时动态设置)replicaof redis-master 6379# 从节点只读模式 (推荐开启)replica-read-only yes# 复制超时时间 (容器网络稳定可降低)repl-timeout 60# 无盘复制 (容器环境推荐关闭)repl-diskless-sync no 3. 标准配置文件参考（Redis6为例）################################## 基础配置 #################################### 绑定地址 (容器中建议注释掉或设为 0.0.0.0)# bind 127.0.0.1 -::1bind 0.0.0.0 # 容器内允许所有网络接口访问# 监听端口 (默认6379)port 6379# 保护模式 (生产环境应禁用)protected-mode no # 容器在内部网络运行时关闭# 守护进程模式 (容器中必须设为 no)daemonize no # 容器需要前台运行# 进程PID文件 (容器中通常不需要)# pidfile /var/run/redis.pid# 客户端访问密码requirepass zoran.wang@redis! # 主节点密码# 主从复制密码masterauth zoran.wang@redis! # 必须与requirepass一致################################# 持久化配置 #################################### RDB快照配置 - 生产环境推荐save 900 1 # 900秒(15分钟)内至少1个键变化则保存save 300 10 # 300秒(5分钟)内至少10个键变化save 60 10000 # 60秒内至少10000个键变化# 后台保存出错时停止写入 (生产环境必须开启)stop-writes-on-bgsave-error yes# RDB文件压缩 (推荐开启)rdbcompression yes# RDB校验和 (推荐开启)rdbchecksum yes# RDB文件名dbfilename dump.rdb# 工作目录 (挂载卷位置)dir /data # Podman卷挂载点# AOF持久化配置 (推荐同时开启RDB+AOF)appendonly yes # 开启AOF# AOF文件名appendfilename appendonly.aof# AOF同步策略 (生产环境折衷方案)appendfsync everysec # 每秒同步，兼顾性能与安全# AOF重写时不同步 (提升性能)no-appendfsync-on-rewrite no# AOF自动重写阈值auto-aof-rewrite-percentage 100 # 增长100%时重写auto-aof-rewrite-min-size 64mb # 最小64MB触发重写# AOF加载时错误处理 (生产环境必须)aof-load-truncated yes############################## 主从复制配置 #################################### 主节点密码 (容器间通信推荐设置)# masterauth your_strong_password# 从节点复制配置 (启动时动态设置)# replicaof masterip masterport# 从节点只读模式 (推荐开启)replica-read-only yes# 复制超时时间 (容器网络稳定可降低)repl-timeout 60# 无盘复制 (容器环境推荐关闭)repl-diskless-sync no# 后台传输延迟 (默认关闭)repl-disable-tcp-nodelay no# 复制积压缓冲区大小 (提升故障转移能力)repl-backlog-size 128mb # 哨兵模式推荐值# 积压缓冲区保留时间repl-backlog-ttl 3600 # 1小时############################### 安全配置 ####################################### 访问密码 (生产环境必须设置)requirepass your_strong_password_here # 替换为强密码# 危险命令重命名 (生产环境必须)rename-command FLUSHDB # 禁用FLUSHDBrename-command FLUSHALL # 禁用FLUSHALLrename-command CONFIG REDIS-CONFIG # 重命名CONFIG# 最大客户端连接数maxclients 10000 # 根据容器资源调整############################### 资源限制 ####################################### 最大内存限制 (容器环境必须设置)maxmemory 2gb # 设置为容器内存限制的80-90%# 内存淘汰策略 (推荐allkeys-lru)maxmemory-policy allkeys-lru# 关闭透明大页 (容器中通常不需要)# disable-thp yes############################### 日志配置 ####################################### 日志级别 (生产环境推荐notice)loglevel notice# 日志文件 (容器中推荐输出到stdout)# logfile /var/log/redis/redis.loglogfile # 输出到标准输出# 数据库数量databases 16############################## 慢查询日志 ###################################### 慢查询阈值 (单位微秒)slowlog-log-slower-than 10000 # 10毫秒# 慢查询记录长度slowlog-max-len 128 # 保留128条记录############################ 事件通知 ######################################### 键空间通知 (按需开启)# notify-keyspace-events ########################### 高级配置 ########################################## 客户端超时 (容器网络稳定可降低)timeout 30 # 30秒无活动断开连接# TCP keepalive (推荐开启)tcp-keepalive 300 # 5分钟# 协议版本 (推荐新版)protocol-version 3 # RESP3协议# 内核OOM控制 (容器环境重要)oom-score-adj no # 不调整OOM分数# 动态HZ (推荐开启)dynamic-hz yes# 子进程调度 (Linux容器推荐)linux-tcp-backlog 511 # 提高TCP队列replica-ignore-maxmemory yes # 从节点忽略maxmemory########################### 容器优化参数 ####################################### 禁用THP (透明大页)disable-thp yes # 避免内存分配延迟# 后台进程优先级bgrewriteaof-schedule-delay 100 # AOF重写延迟(ms)bgsave-schedule-delay 100 # RDB保存延迟# 容器内时钟源优化 (解决时间跳变问题)slowclock-source tsc # 使用TSC时钟源########################### 未使用但重要的参数 ################################## 集群模式 (哨兵模式中不需要)# cluster-enabled no# TLS配置 (内网容器通信通常不需要)# tls-port 6379# tls-cert-file redis.crt# tls-key-file redis.key# 系统控制 (容器中由Podman管理)# syslog-enabled no# syslog-ident redis# 多线程IO (Redis 6+特性，测试环境评估)# io-threads 4# io-threads-do-reads no# 延迟监控 (调试使用)# latency-monitor-threshold 0# 子进程CPU亲和性 (物理机优化)# set-cpu-affinity 0,2,4,6# 内存碎片整理 (高负载环境评估)# activedefrag yes# active-defrag-ignore-bytes 100mb# active-defrag-threshold-lower 10 4. 使用命令部署# 启动Redis主节点，分配固定IP 10.89.1.35podman run -d \\ --name redis-master \\ -p 6379:6379 \\ --ip 10.89.1.35 \\ --restart always \\ -v redis_master_data:/data \\ -v ~/dev/podman/conf/redis-master.conf:/etc/redis.conf:z \\ --network redis_sentinel_net \\ --cpus=0.2 \\ --memory=100m \\ -e TZ=Asia/Shanghai \\ docker.io/arm64v8/redis:latest \\ redis-server /etc/redis.conf# 验证主节点IPMASTER_IP=$(podman inspect -f .NetworkSettings.Networks.redis_sentinel_net.IPAddress redis-master)echo Master IP: $MASTER_IP# 测试主节点podman exec -it redis-master /bin/bashredis-cli# 进入到redis命令行后需要鉴权auth zoran.wang@redis!# 随便输入点命令玩玩pingset hello redis!get hello# exit退出容器到宿主机exit# 启动Redis从节点，注意映射到宿主机的端口号有差异podman run -d \\ --name redis-slave1 \\ -p 6389:6389 \\ -v redis_slave1_data:/data \\ -v ~/dev/podman/conf/redis-slave.conf:/etc/redis.conf:z \\ --network redis_sentinel_net \\ --cpus=0.2 \\ --memory=100m \\ -e TZ=Asia/Shanghai \\ docker.io/arm64v8/redis:latest \\ redis-server /etc/redis.confpodman run -d \\ --name redis-slave2 \\ -p 6399:6389 \\ -v redis_slave2_data:/data \\ -v ~/dev/podman/conf/redis-slave.conf:/etc/redis.conf:z \\ --network redis_sentinel_net \\ --cpus=0.2 \\ --memory=100m \\ -e TZ=Asia/Shanghai \\ docker.io/arm64v8/redis:latest \\ redis-server /etc/redis.conf 5. 使用脚本部署（推荐）以上的命令可以写成脚本，生产建议使用脚本部署，该脚本使用DeepSeek生成。 redis-master.sh创建文件edis-master.sh，复制如下内容： #!/bin/bash# Redis 主节点部署脚本# 作者：王卓# 日期：$(date +%Y-%m-%d)set -euo pipefail # 启用严格错误检查# 配置参数CONTAINER_NAME=redis-masterNETWORK_NAME=redis_sentinel_netVOLUME_NAME=redis_master_dataCONFIG_PATH=$HOME/dev/podman/conf/redis-master.confIMAGE=docker.io/arm64v8/redis:latestCPU=0.2MAX_SIZE=100MPORT=6379# 检查必要文件是否存在check_dependencies() # 检查配置文件是否存在 if [[ ! -f $CONFIG_PATH ]]; then echo 错误：Redis 配置文件不存在: $CONFIG_PATH exit 1 fi # 检查镜像是否可用 if ! podman image exists $IMAGE; then echo 正在拉取 Redis 镜像... podman pull $IMAGE || echo 错误：无法拉取 Redis 镜像 exit 1 fi# 创建网络（如果不存在）create_network() if ! podman network exists $NETWORK_NAME; then echo 创建网络 $NETWORK_NAME... podman network create $NETWORK_NAME fi# 主部署函数deploy_redis_master() echo 正在部署 Redis 主节点... podman run -d \\ --name $CONTAINER_NAME \\ --ip 10.89.1.35 \\ --restart always \\ -p $PORT:6379 \\ -v $VOLUME_NAME:/data \\ -v $CONFIG_PATH:/etc/redis.conf:z \\ --network $NETWORK_NAME \\ --cpus=$CPU \\ --memory=$MAX_SIZE \\ -e TZ=Asia/Shanghai \\ $IMAGE \\ redis-server /etc/redis.conf echo ✅ Redis 主节点已成功部署 echo 容器名称: $CONTAINER_NAME echo 访问端口: $PORT# 执行部署main() check_dependencies create_network # 检查容器是否已存在 if podman container exists $CONTAINER_NAME; then read -rp 容器 $CONTAINER_NAME 已存在，是否重新创建？[y/N] response if [[ $response =~ ^[Yy]$ ]]; then echo 删除现有容器... podman rm -f $CONTAINER_NAME else echo 操作已取消 exit 0 fi fi deploy_redis_master# 执行主函数main# 获取主节点IPIP=$(podman inspect -f .NetworkSettings.Networks.redis_sentinel_net.IPAddress redis-master)echo 容器内IP: $IP redis-slave.sh创建文件edis-slave.sh，复制如下内容： #!/bin/bash# Redis 从节点部署脚本# 支持部署多个从节点实例# 修复了 POSIX shell 兼容性问题set -euo pipefail # 启用严格错误检查# 全局配置NETWORK_NAME=redis_sentinel_netIMAGE=docker.io/arm64v8/redis:latestCONFIG_BASE_DIR=$HOME/dev/podman/conf# 从节点配置 - 使用索引数组代替关联数组SLAVE_NAMES=(redis-slave1 redis-slave2)SLAVE_VOLUMES=(redis_slave1_data redis_slave2_data)SLAVE_CONFIGS=(redis-slave.conf redis-slave.conf)SLAVE_PORTS=(6389 6399)# 检查依赖项check_dependencies() # 检查镜像是否可用 if ! podman image exists $IMAGE; then echo 正在拉取 Redis 镜像... podman pull $IMAGE || echo 错误：无法拉取 Redis 镜像 exit 1 fi # 检查配置目录 if [[ ! -d $CONFIG_BASE_DIR ]]; then echo 错误：配置目录不存在 $CONFIG_BASE_DIR exit 1 fi# 创建网络（如果不存在）create_network() if ! podman network exists $NETWORK_NAME; then echo 创建网络 $NETWORK_NAME... podman network create $NETWORK_NAME fi# 检查容器是否存在并处理handle_existing_container() local container_name=$1 if podman container exists $container_name; then read -rp 容器 $container_name 已存在，是否重新创建？[y/N] response if [[ $response =~ ^[Yy]$ ]]; then echo 删除现有容器 $container_name... podman rm -f $container_name return 0 else echo 跳过 $container_name 部署 return 1 fi fi return 0# 部署单个从节点deploy_redis_slave() local index=$1 local name=$SLAVE_NAMES[$index] local volume=$SLAVE_VOLUMES[$index] local config=$SLAVE_CONFIGS[$index] local port=$SLAVE_PORTS[$index] local config_path=$CONFIG_BASE_DIR/$config # 检查配置文件 if [[ ! -f $config_path ]]; then echo 警告：配置文件不存在 $config_path，使用默认配置 config_path=/dev/null # 使用镜像内默认配置 fi echo 正在部署从节点 $name... podman run -d \\ --name $name \\ -p $port:6379 \\ -v $volume:/data \\ -v $config_path:/etc/redis.conf:z \\ --network $NETWORK_NAME \\ --cpus=0.2 \\ --memory=100m \\ -e TZ=Asia/Shanghai \\ $IMAGE \\ redis-server /etc/redis.conf echo ✅ Redis 从节点 $name 已部署 echo - 数据卷: $volume echo - 外部端口: $port echo - 配置文件: $config_path# 主部署函数deploy_all_slaves() for index in $!SLAVE_NAMES[@]; do echo echo ===== 处理从节点 $SLAVE_NAMES[$index] ===== if handle_existing_container $SLAVE_NAMES[$index]; then deploy_redis_slave $index fi done# 主执行流程main() echo ====== 开始部署 Redis 从节点 ====== check_dependencies create_network deploy_all_slaves echo echo ====== 部署完成 ====== podman ps --filter name=redis-slave* --format table .Names\\t.Ports\\t.Status# 执行主函数main 6. 验证容器部署情况# 查看容器状态是否为UPpodman ps -a# 查看容器日志podman logs -f redis-masterpodman logs -f redis-slave1podman logs -f redis-slave2# 进入到从节点查看刚才主节点存入的数据podman exec -it redis-slave2 /bin/bashredis-cliauth zoran.wang@redis!keys *get hello 二、部署Sentinel哨兵（一）准备好配置文件新建配置文件 sentinel.conf，复制如下内容： # ==================== 基础配置 ====================port 26379# 容器中必须设为nodaemonize no# 输出到标准输出，方便容器日志收集logfile # 持久化数据目录dir /data# ==================== 监控的主节点配置 ====================# 格式：sentinel monitor 主节点名称 IP 端口 仲裁数sentinel monitor mymaster 10.89.1.35 6379 2# 主节点密码（必须与redis-master的requirepass一致）sentinel auth-pass mymaster zoran.wang@redis!# ==================== 故障判定参数 ====================# 主节点无响应超过5000毫秒视为下线sentinel down-after-milliseconds mymaster 5000# 故障转移超时时间（毫秒）sentinel failover-timeout mymaster 10000# 并行同步的新从节点数量sentinel parallel-syncs mymaster 1# ==================== 安全加固配置 ====================# Sentinel自身密码（Redis 6.2+）# 用户名sentinel sentinel-user default# 密码sentinel sentinel-pass zoran.wang@sentinel!# 禁止执行危险命令# sentinel rename-command SHUTDOWN # sentinel rename-command CONFIG REDIS-CONFIG# 安全设置sentinel deny-scripts-reconfig yes# ==================== 高级调优参数 ====================# 日志级别（notice适合生产环境）loglevel notice# 输出到标准输出，方便容器日志收集logfile # 通知脚本（可选）# sentinel notification-script mymaster /scripts/notify.sh# 客户端连接数限制maxclients 10000# 保护模式关闭（容器网络内部使用）protected-mode no （二）哨兵的权限问题1. 原因分析 文件权限问题： 容器内的 Redis Sentinel 进程默认以 redis 用户（UID 999）运行。 挂载的宿主机文件 ~/dev/podman/conf/sentinel.conf 未赋予 redis 用户足够的写权限。 在MacOS系统中，podman本质上是个虚拟机，MacOS用户根本看不到虚拟机中的redis用户，属于不同层面，没办法赋予权限； 而Linux系统不一样，可以理解成Linux系统本身就是一个容器，与podman其他容器是同级别的，所以权限正常就能写。 当 Sentinel 尝试更新配置（如选举新主节点）时，会触发写入操作，导致权限错误。 SELinux 限制（如果宿主机启用 SELinux）： 即使文件权限正确，SELinux 也可能阻止容器进程写入宿主机文件系统。 总结：需要理解容器的概念，容器中的进程对宿主机的文件很多情况只能在启动的时候读一次，不能进行写操作。在 2. Linux（podman）解决方案修改文件权限调整安全策略即可 # 确保配置文件目录存在mkdir -p ~/dev/podman/conf/# 修改文件所有者为容器内 redis 用户（UID 999）sudo chown 999:999 ~/dev/podman/conf/sentinel.conf# 赋予读写权限chmod 644 ~/dev/podman/conf/sentinel.conf# 调整SELinux标签# 使用 :Z 重新标记文件podman run ... \\ -v ~/dev/podman/conf/sentinel.conf:/etc/sentinel.conf:Z \\ ... 3. MacOS（podman）解决方案MacBook上的podman实际上是运行在系统上的一个虚拟机，podman里面的容器无法对宿主机的文件进行写操作，只能在启动的时候读一次。 podman创建的数据卷是在虚拟机中的，我们可以把sentinel.conf挂载到数据卷sentinel_conf_data上，然后在创建容器时，用数据卷文件挂载取代本地文件挂载，sentinel进程（redis用户）就可以进行读写。 # ==========使用Podman数据卷解决权限问题，这里以一个节点为例==========# 创建Sentinel配置文件专用数据卷podman volume create sentinel_conf_data# 拉取兼容 M 芯片的镜像podman pull docker.io/arm64v8/busybox:latest# 复制配置文件到专用数据卷podman run --rm\\ -v ~/dev/podman/conf:/source:ro \\ -v sentinel_conf_data:/config \\ docker.io/arm64v8/busybox:latest \\ cp /source/sentinel.conf /config/sentinel.conf# 查看持久化卷的内容# 添加 --privileged 选项（仅限开发环境）podman run --rm --privileged \\ -v sentinel_conf_data:/volume:ro \\ docker.io/arm64v8/busybox:latest \\ ls -l /volume# 启动临时容器设置权限podman run -d --name sentinel-temp \\ -v sentinel_conf_data:/config \\ docker.io/arm64v8/redis:latest \\ sleep infinity# 启动临时容器设置权限podman run -d --name sentinel-temp \\ -v sentinel_conf_data:/config \\ docker.io/arm64v8/redis:latest \\ sleep infinity# 修改文件所有权为 redis 用户（UID 999）podman exec sentinel-temp chown 999:999 /config/sentinel.conf# （参考）如果有三个配置文件可以循环执行for i in 1..3; do podman exec sentinel-temp chown 999:999 /config/sentinel-node$i.confdone# 验证权限podman exec sentinel-temp ls -l /config# 清理临时容器podman stop sentinel-temppodman rm sentinel-temp# 清理数据卷（UUID临时）podman volume lspodman volume rm ...podman run -d --name sentinel \\ --network redis_sentinel_net \\ -v sentinel_data:/data \\ -v sentinel_conf_data:/etc/sentinel_conf_data:Z \\ --cpus=0.1 \\ --memory=20m \\ -e TZ=Asia/Shanghai \\ docker.io/arm64v8/redis:latest \\ redis-sentinel /etc/sentinel_conf_data/sentinel-node1.conf# ==============MacOS专属操作==============# podman本质上是个虚拟机，可以用命令进入到命令行podman machine ssh# 在虚拟机内查看卷实际路径sudo ls -l /var/lib/containers/storage/volumes/sentinel_conf_data# 可以进入到该路径下赋权、编辑等操作 4. 云原生最佳实践——Dockerfile（推荐）通过 Dockerfile 构建自定义 Sentinel 镜像，使用环境变量动态配置 Redis 主节点 IP、密码等可变参数，既能保证配置的版本控制，又能保持部署的灵活性。 由于篇幅较长，为了方便阅读，提取为单独的一篇博客《Dockerfile构建个性化Sentinel镜像》。 三、redisinsight# 安装网页工具podman volume create redisinsight_sentinel_data podman run -d \\ --name redisinsight-sentinel \\ -p 5540:5540 \\ -v redisinsight-data:/db \\ --network redis_sentinel_net \\ docker.io/redislabs/redisinsight:latest 注意登录的时候，IP不是localhost，而是下面的命令获取的IP（站在redisinsight的视角，与redis-master都属于容器，访问的时podman中redis-master容器的IP） # 验证主节点IPMASTER_IP=$(podman inspect -f .NetworkSettings.Networks.redis_sentinel_net.IPAddress redis-master)echo Master IP: $MASTER_IP 四、热部署修改挂载的配置文件后，不需要重启容器就能生效。后续补充……","tags":["redis","podman"],"categories":["Linux","Redis"]},{"title":"Oracle迁移TDSQL-语法转换篇","path":"/2025/07/23/OracleToTXSQL/","content":"因为TDSQL兼容MySQL的语法，所以下文中用MySQL的语法替代TDSQL，本文重点关注语法转换。 一、 基础语法差异与迁移 字符串连接： Oracle: || (例如 SELECT Hello || World FROM dual;) MySQL: CONCAT() 函数 (例如 SELECT CONCAT(Hello, World);)。|| 在MySQL中默认是逻辑OR运算符（除非设置SQL_MODE=PIPES_AS_CONCAT，但不推荐依赖此设置）。 迁移： 将所有 || 替换为 CONCAT()。 空字符串与NULL： Oracle: 严格区分空字符串()和NULL。 MySQL: 不严格区分。在大多数上下文中（特别是使用=或比较时），空字符串()被视为等同于NULL。但使用IS NULL和IS NOT NULL时能区分。 迁移： 这是最容易出错的地方！ 仔细检查所有使用 column = 或 column 的条件。通常需要改为 column IS NULL 或 (column IS NULL OR column = ) 或 (column IS NOT NULL AND column )，具体逻辑取决于Oracle中的原始意图。 检查NVLNVL2等处理空值的函数逻辑，确保在MySQL中达到相同效果（MySQL的IFNULLCOALESCE处理NULL，不处理空串）。 伪表 DUAL： Oracle: SELECT SYSDATE FROM dual; SELECT 1+1 FROM dual; (DUAL是单行单列虚拟表) MySQL: SELECT NOW(); SELECT 1+1; (可以直接执行，不需要FROM子句) 迁移： 删除不必要的 FROM dual。 分页查询： Oracle 12c 之前: 使用 ROWNUM 和子查询实现复杂分页。 Oracle 12c+: 使用 OFFSET ... FETCH ...。 MySQL: 使用 LIMIT [offset,] row_count 或 LIMIT row_count OFFSET offset。 迁移： 将Oracle 12c+的 OFFSET ... FETCH ... 直接替换为MySQL的 LIMIT ... OFFSET ... 语法。 将Oracle 12c之前基于ROWNUM的复杂分页逻辑重写为使用LIMIT ... OFFSET ...。通常需要去掉外层包装的子查询。 日期和时间： 获取当前时间: Oracle: SYSDATE (精确到秒), SYSTIMESTAMP (精确到小数秒) MySQL: NOW() (返回DATETIME，精确到秒), CURRENT_TIMESTAMP() (同NOW()), SYSDATE() (每次调用实时获取，可能影响基于语句的复制和某些优化), CURDATE(), CURTIME()。推荐使用 NOW() 或 CURRENT_TIMESTAMP()。 日期加减: Oracle: date_column + INTERVAL 1 DAY, date_column - 7 MySQL: DATE_ADD(date_column, INTERVAL 1 DAY), DATE_SUB(date_column, INTERVAL 7 DAY) 或 date_column + INTERVAL 1 DAY, date_column - INTERVAL 7 DAY (MySQL也支持 +/- INTERVAL 语法，推荐)。 日期截断： Oracle: TRUNC(date_column) (到天), TRUNC(date_column, MM) (到月) MySQL: DATE(date_column) (提取日期部分), LAST_DAY(date_column) (月末), 对于其他截断通常使用 DATE_FORMAT(date_column, %Y-%m-01) (月初) 或组合函数。 日期格式化： Oracle: TO_CHAR(date_column, YYYY-MM-DD HH24:MI:SS) MySQL: DATE_FORMAT(date_column, %Y-%m-%d %H:%i:%s) (注意：%H是24小时制, %i是分钟) 字符串转日期： Oracle: TO_DATE(2023-10-27, YYYY-MM-DD) MySQL: STR_TO_DATE(2023-10-27, %Y-%m-%d) 迁移： 系统性地替换日期相关函数和运算符。特别注意格式模型的不同。 序列 (Sequence)： Oracle: 使用显式的SEQUENCE对象 (CREATE SEQUENCE ...), 通过 sequence_name.NEXTVAL 和 sequence_name.CURRVAL 访问。 MySQL: 使用 AUTO_INCREMENT 属性为主键列自动生成唯一ID (主要用于单表)。对于需要全局序列或多表共享序列，有以下方案： 方案A (推荐)： 创建一个专门的表来模拟序列 (包含 id AUTO_INCREMENT 字段)。通过 INSERT ... ; SELECT LAST_INSERT_ID(); 获取新值。需要小心并发和事务管理。 方案B： 使用MySQL 8.0+的 AUTO_INCREMENT 的持久化特性（innodb_autoinc_lock_mode=2 - interleaved lock mode）结合 LAST_INSERT_ID()，但这主要解决批量插入的间隙问题，不完全等同于独立序列。 方案C (谨慎)： 使用第三方工具或自定义函数。 迁移： 对于主键，优先使用AUTO_INCREMENT。对于非主键序列需求，采用方案A（模拟序列表）并重写所有 NEXTVALCURRVAL 的访问逻辑。 数据类型映射： 常用映射: NUMBER(p, s) - DECIMAL(p, s) (精确数值) VARCHAR2(n [CHAR|BYTE]) - VARCHAR(n) (MySQL的VARCHAR长度指字符数，需确认n是否足够，注意UTF8MB4字符可能占4字节) NVARCHAR2(n) - NVARCHAR(n) 或 VARCHAR(n) CHARACTER SET utf8mb4 (存储Unicode) DATE - DATETIME 或 DATE (Oracle DATE包含时间部分，MySQL DATE只有日期。如果需要时间，用DATETIME或TIMESTAMP) TIMESTAMP - TIMESTAMP (注意MySQL TIMESTAMP范围是’1970-01-01 00:00:01’ UTC 到 ‘2038-01-19 03:14:07’ UTC, 且有时区转换行为) 或 DATETIME (范围’1000-01-01 00:00:00’到’9999-12-31 23:59:59’, 无时区转换) CLOB - LONGTEXT BLOB - LONGBLOB RAW(n) - VARBINARY(n) LONG - LONGTEXT 或 LONGBLOB (已废弃类型) 迁移： 根据实际存储内容和需求仔细选择最合适的MySQL类型。特别注意日期时间类型的选择和TIMESTAMP的范围限制。 二、 函数映射与替换 空值处理： NVL(expr1, expr2) - IFNULL(expr1, expr2) 或 COALESCE(expr1, expr2) NVL2(expr1, expr2, expr3) - IF(expr1 IS NOT NULL, expr2, expr3) 或 CASE WHEN expr1 IS NOT NULL THEN expr2 ELSE expr3 END COALESCE(expr1, expr2, ..., exprn) (两者都有，语法相同) 条件逻辑： DECODE(value, search1, result1, search2, result2, ..., default) - CASE value WHEN search1 THEN result1 WHEN search2 THEN result2 ... ELSE default END CASE ... END (两者语法基本相同，是首选) 字符串函数： SUBSTR(string, start [, length]) - SUBSTRING(string, start [, length]) (注意：Oracle的start可为负表示从末尾数，MySQL也支持负数start) INSTR(string, substring [, start [, occurrence]]) - LOCATE(substring, string [, start]) (MySQL的LOCATE只返回第一次出现的位置，要模拟occurrence需要更复杂逻辑或自定义函数) LENGTH(string) - CHAR_LENGTH(string) 或 LENGTH(string) (Oracle LENGTH按字符数，MySQL LENGTH()按字节数, CHAR_LENGTH()按字符数。强烈推荐在涉及多字节字符集时使用CHAR_LENGTH()) LPAD(string, length [, pad_string]) RPAD(...) (两者都有，语法相同) UPPER(string) LOWER(string) (两者都有，语法相同) TRIM([[LEADING|TRAILING|BOTH] trim_character FROM] string) (两者语法基本相同) REPLACE(string, search_string, replacement_string) (两者都有，语法相同) 聚合函数： COUNT, SUM, AVG, MIN, MAX (两者语法基本相同) LISTAGG(measure_expr [, delimiter]) WITHIN GROUP (ORDER BY sort_expr) - GROUP_CONCAT([DISTINCT] expr [, separator] [ORDER BY ... [ASC|DESC]]) (注意排序和分隔符位置语法差异) 分析函数 (窗口函数)： Oracle有丰富的分析函数 (ROW_NUMBER(), RANK(), DENSE_RANK(), LEAD(), LAG(), SUM() OVER(), ...) MySQL 8.0+ 已支持标准SQL窗口函数，语法与Oracle高度相似。 这是迁移到MySQL 8.0+的巨大优势！ 迁移： 如果使用MySQL 8.0+，大部分分析函数可以直接迁移或做极小语法调整（如别名引用）。如果使用MySQL 5.7或更低版本，需要彻底重写为使用变量(@var)模拟或复杂的自连接子查询，工作量巨大且性能可能不佳。强烈建议升级到MySQL 8.0+以支持窗口函数。 其他常用函数： TO_CHAR(number/date, format) - 数字: FORMAT(number, decimals) (注意返回字符串带千分位) 或 CAST(number AS CHAR)；日期: DATE_FORMAT(date, format) TO_NUMBER(string) - CAST(string AS DECIMAL) 或 CONVERT(string, DECIMAL) SYSDATE - NOW() 或 CURRENT_TIMESTAMP() ADD_MONTHS(date, n) - DATE_ADD(date, INTERVAL n MONTH) MONTHS_BETWEEN(date1, date2) - 需计算：TIMESTAMPDIFF(MONTH, date2, date1) + 调整 (注意Oracle结果含小数部分表示不足月的天数差异，精确模拟较复杂) LAST_DAY(date) (两者都有) NEXT_DAY(date, DAYOFWEEK) - 需要计算：DATE_ADD(date, INTERVAL (7 - WEEKDAY(date) + CASE WHEN target_dow_index WEEKDAY(date) THEN target_dow_index - WEEKDAY(date) ELSE 7 - WEEKDAY(date) + target_dow_index END) DAY) (很复杂，通常建议应用层处理或自定义函数) DBMS_RANDOM.VALUE - RAND() (生成0-1随机浮点数) 三、 高级特性与对象迁移 存储过程、函数、包： 语法差异巨大： PLSQL (Oracle) vs MySQL的存储过程语言（基于SQLPSM）。包(Package)在MySQL中没有直接对应概念。 迁移策略： 重构： 这是最彻底但也最耗时的方式。将Oracle的PLSQL代码（尤其是使用了大量Oracle特有函数、特性、游标、异常处理的代码）用MySQL的存储过程函数语法重写。 分解包： 将Oracle包中的存储过程、函数、变量、游标定义拆分到独立的MySQL存储过程、函数、临时表会话变量中。 工具转换+人工重写： 使用迁移工具进行初步转换，然后投入大量精力进行人工审查、测试和重写。 业务逻辑上移： 考虑是否可以将部分逻辑移到应用层代码中实现，减少对数据库存储过程的依赖。 触发器： 语法 (CREATE TRIGGER ... BEFORE/AFTER ... ON ... FOR EACH ROW ...) 基本相似。 迁移注意点： 替换触发器内部使用的Oracle特有函数和语法（如 :NEW, :OLD 引用新旧行在MySQL中写法相同）。 注意MySQL的触发器不允许在触发器中调用存储过程（MySQL 5.7及之前）或对本表进行修改（可能导致递归循环）。MySQL 8.0允许在触发器中调用存储过程。 仔细测试触发器逻辑，确保在MySQL中行为一致。 视图： 语法 (CREATE VIEW ... AS SELECT ...) 基本相同。 迁移： 主要工作是确保视图定义中的SQL语句本身（涉及到的表、列、函数、条件）在MySQL中能正确执行并返回预期结果。替换其中的Oracle特有语法和函数。 索引与约束： 主键、外键、唯一约束、非空约束： 语法 (PRIMARY KEY, FOREIGN KEY ... REFERENCES ..., UNIQUE, NOT NULL) 基本相同，迁移时保留即可。 检查约束： Oracle支持，MySQL直到8.0.16才真正支持标准的CHECK约束（之前版本会解析但忽略）。迁移到MySQL 8.0.16+： 可以迁移CHECK约束。迁移到更低版本： 约束逻辑需要通过触发器或在应用层实现。 函数索引： Oracle支持。MySQL 8.0.13+支持在InnoDB上创建函数索引（称为Generated Columns Index）。迁移策略： 如果使用MySQL 8.0.13+，可以考虑使用Generated Column+索引模拟。否则，需要重写查询避免在WHERE条件中对列使用函数。 事务与锁： 基本语法 (START TRANSACTION, COMMIT, ROLLBACK, SAVEPOINT) 相同。 隔离级别： Oracle默认通常是READ COMMITTED。 MySQL InnoDB默认是REPEATABLE READ。行为有显著差异！ (如MySQL RR通过快照避免不可重复读和幻读，Oracle RC可能遇到)。迁移： 评估应用对隔离级别的依赖。可以在MySQL连接会话或全局设置隔离级别 (SET TRANSACTION ISOLATION LEVEL READ COMMITTED;)。务必进行并发测试。 锁机制： 两者都是基于锁+MVCC。理解差异对于高性能应用很重要，但SQL语法层面通常不需要修改。 层次查询 (CONNECT BY)： Oracle: 使用 START WITH ... CONNECT BY [PRIOR] ... 进行递归查询。 MySQL 8.0+: 使用标准SQL的递归公用表表达式 WITH RECURSIVE cte_name AS (...) SELECT ... FROM cte_name。 迁移： 如果使用MySQL 8.0+，将CONNECT BY查询重写为WITH RECURSIVE语法。这是结构性的重写，需要理解递归CTE原理。低版本MySQL无内置支持，需要应用层递归或使用存储过程模拟，非常复杂。 四、 字符集与排序规则 Oracle: 常用AL32UTF8 (UTF-8)。 MySQL: 强烈推荐使用 utf8mb4 字符集和 utf8mb4_0900_ai_ci (或合适的) 排序规则。 utf8mb4 是真正的UTF-8，支持4字节字符（如emoji表情）。 MySQL旧的utf8只支持3字节字符（已废弃）。 迁移： 确保在MySQL服务器、数据库、表和连接字符串中都明确指定使用 utf8mb4 和合适的排序规则 (collation)。排序规则影响字符串比较和排序规则，需根据业务需求选择（如是否区分大小写 _ci_cs，是否区分重音 _ai_as）。测试字符数据的正确存储、检索和比较。 关键挑战与注意事项 存储过程包高级函数： 最大的技术难点，需要深入理解两边语法和特性，可能涉及大量重写。 隐式行为差异： 空字符串NULL、日期处理、隐式类型转换、默认隔离级别等，容易在测试中遗漏，导致生产环境问题。 性能调优： MySQL的优化器、锁机制、执行计划可能与Oracle不同。迁移后必须进行性能测试和优化（索引、查询重写、参数调整）。 事务与并发控制： 理解REPEATABLE READ与READ COMMITTED的差异对应用并发逻辑的影响。 字符集与编码： 确保utf8mb4正确配置，避免乱码问题。 测试覆盖度： 测试不充分是迁移失败的主要原因。需要全面的测试计划和数据。 人员技能： 团队需要同时熟悉Oracle和MySQL（特别是MySQL 8.0的新特性）。 总结： Oracle迁移到MySQL在SQL层面是一个系统性的工程，涉及大量语法、函数和特性的映射、重写与适配。成功的关键在于深入理解差异、严格的测试、对复杂代码（特别是存储过程）的重点投入以及选择MySQL 8.0+版本。务必做好详细规划、风险评估和充分的测试验证。祝您迁移顺利！","tags":["sql"],"categories":["数据库国产化"]},{"title":"Podman容器化部署&运维","path":"/2025/07/13/almalinux-podman/","content":"podman简介podman vs dockerpodman常用命令DockerFile实际操作","tags":["linux","运维"],"categories":["Linux","Podman"]},{"title":"Almalinux9.6常用服务部署","path":"/2025/07/13/almalinux-base/","content":"虚拟机环境：Almalinux9.6 施工中…","tags":["linux"],"categories":["Linux"]},{"title":"SQL常用语法","path":"/2025/07/13/sql-base/","content":"施工中…","tags":["sql"],"categories":["SQL"]},{"title":"SQL批处理","path":"/2025/07/13/sql-batch/","content":"施工中","tags":["sql"],"categories":["SQL"]},{"title":"SQL中的递归CTE","path":"/2025/07/13/sql-cte/","content":"递归CTE简介基础用法实例操作","tags":["sql"],"categories":["SQL"]},{"title":"关于","path":"/about/index.html","content":"王卓有趣的牛马万里挑一 关于本站 我的笔尖，仅是浅滩的微光， 记录潮汐的絮语，礁石的形状。 这点滴的沙砾，汇不成大陆， 却愿作一粒引路的燧石。 本站建于2025年7月13日，正在慢慢转移资源…尽请期待！"},{"title":"收藏","path":"/bookmark/index.html","content":"…"},{"title":"探索","path":"/explore/index.html","content":"…"},{"title":"Page","path":"/page/index.html","content":"This is a page test."},{"title":"友链","path":"/friends/index.html","content":"友链关于小伙伴们如果宇宙中真有什么终极的逻辑，那就是我们终有一天会在舰桥上重逢，直到生命终结。 [2023-12] 友链失联了怎么办? 添加友链后如果网站长期无法访问，可能会被取消友链！如果您的网站恢复了，可以在申请友链时创建的那条 issue 中评论告知。 朋友们近期的文章 如何交换友链？ 您的网站应满足以下全部条件： 安全合规：合法的、非营利性、无木马植入的 HTTPS 站点。 非空壳网站：网站内发布至少 五篇 原创文章，内容题材不限。 我们需要有一定的有效互动： 先友后链：与博主有至少 半年 的有效互动，例如 issue 或者评论留言。 [2023-12] 友链申请条件变更说明 降低了对商业广告的要求，可以有但是不能太多。提高了「有效互动」的定义：5次更改为半年。 我已满足全部条件，快告诉我如何交换友链！ 如果您没有满足上述条件，即时提交了申请也不会通过哦～ 第一步：新建 Issue新建 GitHub Issue 按照模板格式填写并提交。为了提高图片加载速度，建议优化头像：打开 压缩图 上传自己的头像，将图片尺寸调整到 144px 后下载。将压缩后的图片上传到 去不图床 或者其它稳定的图床并使用此图片链接作为头像。第二步：添加友链并等待管理员审核请添加本站到您的友链中：title: xxxurl: https://xxx.comavatar: screenshot: 待管理员审核通过，添加了 active 标签后，回来刷新即可生效。如果您需要更新自己的友链，请直接修改 issue 内容，大约 3 分钟内生效，无需等待博客重新部署。"},{"title":"朋友文章","path":"/friends/rss/index.html","content":""}]